/*
 * This file was automatically generated by EvoSuite
 * Wed Oct 23 21:20:05 GMT 2024
 */

package org.apache.hadoop.mapreduce.lib.chain;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.shaded.org.mockito.Mockito.*;
import static org.evosuite.runtime.EvoAssertions.*;
import java.time.Month;
import java.util.EnumSet;
import java.util.List;
import java.util.Set;
import javax.security.auth.Subject;
import net.bytebuddy.description.type.TypeDescription;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.DelegationTokenRenewer;
import org.apache.hadoop.fs.HarFileSystem;
import org.apache.hadoop.hdfs.DistributedFileSystem;
import org.apache.hadoop.hdfs.protocol.HdfsConstants;
import org.apache.hadoop.hdfs.web.SWebHdfsFileSystem;
import org.apache.hadoop.hdfs.web.WebHdfsFileSystem;
import org.apache.hadoop.io.EnumSetWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.ObjectWritable;
import org.apache.hadoop.io.TestGenericWritable;
import org.apache.hadoop.io.TestWritable;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.RecordReader;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.TaskInputOutputContext;
import org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup;
import org.apache.hadoop.mapreduce.lib.chain.Chain;
import org.apache.hadoop.mapreduce.lib.map.WrappedMapper;
import org.apache.hadoop.security.UserGroupInformation;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.ViolatedAssumptionAnswer;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true) 
public class Chain_ESTest extends Chain_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      Class<InterruptedException> class0 = InterruptedException.class;
      SWebHdfsFileSystem sWebHdfsFileSystem0 = mock(SWebHdfsFileSystem.class, new ViolatedAssumptionAnswer());
      Chain.KeyValuePair<SWebHdfsFileSystem, InterruptedException> chain_KeyValuePair0 = new Chain.KeyValuePair<SWebHdfsFileSystem, InterruptedException>(sWebHdfsFileSystem0, (InterruptedException) null);
      ObjectWritable objectWritable0 = new ObjectWritable(class0, chain_KeyValuePair0);
      objectWritable0.getConf();
      // Undeclared exception!
      try { 
        Chain.getChainElementConf((Configuration) null, "file:///");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      Chain chain0 = new Chain(true);
      Chain.ChainBlockingQueue<Reducer<InterruptedException, SWebHdfsFileSystem, InterruptedException, InterruptedException>> chain_ChainBlockingQueue0 = chain0.new ChainBlockingQueue<Reducer<InterruptedException, SWebHdfsFileSystem, InterruptedException, InterruptedException>>();
      Reducer<InterruptedException, SWebHdfsFileSystem, InterruptedException, InterruptedException> reducer0 = new Reducer<InterruptedException, SWebHdfsFileSystem, InterruptedException, InterruptedException>();
      chain_ChainBlockingQueue0.enqueue(reducer0);
      chain_ChainBlockingQueue0.dequeue();
      LongWritable.DecreasingComparator longWritable_DecreasingComparator0 = new LongWritable.DecreasingComparator();
      Configuration configuration0 = longWritable_DecreasingComparator0.getConf();
      Class<InterruptedException> class0 = InterruptedException.class;
      Class<SWebHdfsFileSystem> class1 = SWebHdfsFileSystem.class;
      Class<InterruptedException> class2 = InterruptedException.class;
      Class<InterruptedException> class3 = InterruptedException.class;
      String string0 = "#+";
      // Undeclared exception!
      Chain.setReducerConf(configuration0, class0, class1, class2, class3, configuration0, "#+");
  }

  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      Chain chain0 = new Chain(false);
      Configuration configuration0 = new Configuration(false);
      Chain.getIndex(configuration0, "pJts3ZNgp,Z$aE");
      chain0.joinAllThreads();
      Class<InterruptedException> class0 = InterruptedException.class;
      TestWritable.SimpleWritableComparable testWritable_SimpleWritableComparable0 = new TestWritable.SimpleWritableComparable();
      testWritable_SimpleWritableComparable0.getConf();
      Class<InterruptedException> class1 = InterruptedException.class;
      // Undeclared exception!
      try { 
        Chain.setMapperConf(false, (Configuration) null, class0, class0, class0, class1, configuration0, 1259, ">8rkF:A");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      String string0 = Chain.MAPPER_OUTPUT_KEY_CLASS;
      Chain chain0 = new Chain(false);
      JobConf jobConf0 = new JobConf(false);
      boolean boolean0 = true;
      // Undeclared exception!
      try { 
        Chain.checkReducerAlreadySet(false, jobConf0, "org.apache.hadoop.mapreduce.lib.chain.Chain$ChainRecordWriter", true);
        fail("Expecting exception: IllegalStateException");
      
      } catch(IllegalStateException e) {
         //
         // A Mapper can be added to the chain only after the Reducer has been set
         //
         verifyException("org.apache.hadoop.mapreduce.lib.chain.Chain", e);
      }
  }

  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      String string0 = Chain.MAPPER_OUTPUT_KEY_CLASS;
      Chain chain0 = new Chain(false);
      JobConf jobConf0 = new JobConf(false);
      // Undeclared exception!
      try { 
        Chain.checkReducerAlreadySet(false, jobConf0, "org.apache.hadoop.mapreduce.lib.chain.Chain$ChainRecordWriter", true);
        fail("Expecting exception: IllegalStateException");
      
      } catch(IllegalStateException e) {
         //
         // A Mapper can be added to the chain only after the Reducer has been set
         //
         verifyException("org.apache.hadoop.mapreduce.lib.chain.Chain", e);
      }
  }

  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      boolean boolean0 = false;
      String string0 = Chain.CHAIN_REDUCER;
      Chain chain0 = new Chain(false);
      Configuration configuration0 = new Configuration(true);
      // Undeclared exception!
      Chain.checkReducerAlreadySet(false, configuration0, "mapreduce.chain.reducer", true);
  }

  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      Chain chain0 = new Chain(true);
      // Undeclared exception!
      try { 
        chain0.runMapper((TaskInputOutputContext) null, (-1238));
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      Chain chain0 = new Chain(false);
      Configuration configuration0 = new Configuration(false);
      JobConf jobConf0 = new JobConf(false);
      Class<InterruptedException> class0 = InterruptedException.class;
      Class<WebHdfsFileSystem> class1 = WebHdfsFileSystem.class;
      Class<InterruptedException> class2 = InterruptedException.class;
      Class<InterruptedException> class3 = InterruptedException.class;
      // Undeclared exception!
      try { 
        Chain.setMapperConf(false, configuration0, class1, class2, class3, class0, jobConf0, (-1280), "mapreduce.reduce.java.opts");
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // org.apache.hadoop.io.serializer.WritableSerialization cannot be cast to org.apache.hadoop.io.serializer.Serialization
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      boolean boolean0 = true;
      Chain chain0 = new Chain(true);
      Chain chain1 = new Chain(true);
      Chain.ChainBlockingQueue<InterruptedException> chain_ChainBlockingQueue0 = chain1.new ChainBlockingQueue<InterruptedException>();
      Class<InterruptedException> class0 = InterruptedException.class;
      String string0 = "w{|]s%B ]sgjUL`0";
      TestGenericWritable.FooGenericWritable testGenericWritable_FooGenericWritable0 = new TestGenericWritable.FooGenericWritable();
      testGenericWritable_FooGenericWritable0.getConf();
      // Undeclared exception!
      try { 
        Chain.getChainElementConf((Configuration) null, "w{|]s%B ]sgjUL`0");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      TestGenericWritable.Baz testGenericWritable_Baz0 = new TestGenericWritable.Baz();
      testGenericWritable_Baz0.getConf();
      Chain chain0 = new Chain(false);
      Chain.checkReducerAlreadySet(true, (Configuration) null, "org.apache.hadoop.mapreduce.lib.chain.Chain$KeyValuePair", false);
      Chain.ChainBlockingQueue<Chain.KeyValuePair<?, ?>> chain_ChainBlockingQueue0 = chain0.createBlockingQueue();
      assertNotNull(chain_ChainBlockingQueue0);
  }

  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      JobConf jobConf0 = new JobConf(false);
      // Undeclared exception!
      try { 
        Chain.getChainElementConf(jobConf0, "");
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // org.apache.hadoop.io.serializer.WritableSerialization cannot be cast to org.apache.hadoop.io.serializer.Serialization
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      Chain chain0 = new Chain(false);
      Configuration configuration0 = new Configuration(false);
      Chain.getIndex(configuration0, "pJts3ZNgp,Z$aE");
      // Undeclared exception!
      try { 
        Chain.getChainElementConf(configuration0, "");
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // org.apache.hadoop.io.serializer.WritableSerialization cannot be cast to org.apache.hadoop.io.serializer.Serialization
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      Chain chain0 = new Chain(true);
      Configuration configuration0 = new Configuration(true);
      // Undeclared exception!
      Chain.getIndex(configuration0, "pJts3ZNgp,Z$aE");
  }

  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      TestGenericWritable.Baz testGenericWritable_Baz0 = new TestGenericWritable.Baz();
      testGenericWritable_Baz0.getConf();
      Class<Month> class0 = Month.class;
      Class<InterruptedException> class1 = InterruptedException.class;
      Class<InterruptedException> class2 = InterruptedException.class;
      Chain.validateKeyValueTypes(true, (Configuration) null, class1, class0, class2, class0, (-1224), "p%Hd] Dh@*");
      Chain chain0 = new Chain(true);
      chain0.createBlockingQueue();
      Class<InterruptedException> class3 = InterruptedException.class;
      // Undeclared exception!
      try { 
        Chain.validateKeyValueTypes(false, (Configuration) null, class2, class0, class3, class3, 1263, "org.apache.hadoop.mapreduce.lib.chain.Chain$ReduceRunner");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      Chain chain0 = new Chain(false);
      chain0.joinAllThreads();
      JobConf jobConf0 = new JobConf(false);
      Class<WebHdfsFileSystem> class0 = WebHdfsFileSystem.class;
      Class<InterruptedException> class1 = InterruptedException.class;
      Class<InterruptedException> class2 = InterruptedException.class;
      Class<SWebHdfsFileSystem> class3 = SWebHdfsFileSystem.class;
      Chain.validateKeyValueTypes(true, jobConf0, class0, class1, class2, class3, 0, "metric info");
      assertEquals((-1L), JobConf.DISABLED_MEMORY_LIMIT);
  }

  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      Chain chain0 = new Chain(false);
      Configuration configuration0 = new Configuration(false);
      configuration0.getStrings("mapreduce.chain.mapper.input.value.class");
      Class<WebHdfsFileSystem> class0 = WebHdfsFileSystem.class;
      Class<InterruptedException> class1 = InterruptedException.class;
      Class<InterruptedException> class2 = InterruptedException.class;
      Class<InterruptedException> class3 = InterruptedException.class;
      // Undeclared exception!
      try { 
        Chain.validateKeyValueTypes(false, configuration0, class2, class0, class3, class1, 1231, "|X8?t.OhBf");
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // org.apache.hadoop.io.serializer.WritableSerialization cannot be cast to org.apache.hadoop.io.serializer.Serialization
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      Chain chain0 = new Chain(false);
      chain0.joinAllThreads();
      JobConf jobConf0 = new JobConf(false);
      Class<InterruptedException> class0 = InterruptedException.class;
      Class<InterruptedException> class1 = InterruptedException.class;
      Class<WebHdfsFileSystem> class2 = WebHdfsFileSystem.class;
      Class<InterruptedException> class3 = InterruptedException.class;
      // Undeclared exception!
      try { 
        Chain.setMapperConf(true, jobConf0, class1, class0, class2, class3, jobConf0, 1564, "");
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // org.apache.hadoop.io.serializer.WritableSerialization cannot be cast to org.apache.hadoop.io.serializer.Serialization
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      JobConf jobConf0 = new JobConf(false);
      // Undeclared exception!
      try { 
        Chain.getChainElementConf(jobConf0, (String) null);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // org.apache.hadoop.io.serializer.WritableSerialization cannot be cast to org.apache.hadoop.io.serializer.Serialization
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      boolean boolean0 = false;
      JobConf jobConf0 = new JobConf(false);
      String string0 = null;
      // Undeclared exception!
      try { 
        Chain.getChainElementConf(jobConf0, (String) null);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // org.apache.hadoop.io.serializer.WritableSerialization cannot be cast to org.apache.hadoop.io.serializer.Serialization
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      boolean boolean0 = false;
      Chain chain0 = new Chain(false);
      DistributedFileSystem distributedFileSystem0 = new DistributedFileSystem();
      HarFileSystem harFileSystem0 = new HarFileSystem(distributedFileSystem0);
      harFileSystem0.getConf();
      // Undeclared exception!
      try { 
        chain0.setup((Configuration) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.mapreduce.lib.chain.Chain", e);
      }
  }

  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      Class<WrappedMapper> class0 = WrappedMapper.class;
      Chain chain0 = new Chain(false);
      TestGenericWritable.FooGenericWritable testGenericWritable_FooGenericWritable0 = new TestGenericWritable.FooGenericWritable();
      testGenericWritable_FooGenericWritable0.getConf();
      Class<InterruptedException> class1 = InterruptedException.class;
      Class<InterruptedException> class2 = InterruptedException.class;
      Class<InterruptedException> class3 = InterruptedException.class;
      // Undeclared exception!
      try { 
        Chain.setReducerConf((Configuration) null, class2, class0, class1, class3, (Configuration) null, (String) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      Chain chain0 = new Chain(true);
      Class<HdfsConstants.DatanodeReportType> class0 = HdfsConstants.DatanodeReportType.class;
      EnumSet<HdfsConstants.DatanodeReportType> enumSet0 = EnumSet.noneOf(class0);
      EnumSet<HdfsConstants.DatanodeReportType> enumSet1 = enumSet0.clone();
      Class<HdfsConstants.DatanodeReportType> class1 = HdfsConstants.DatanodeReportType.class;
      EnumSetWritable<HdfsConstants.DatanodeReportType> enumSetWritable0 = new EnumSetWritable<HdfsConstants.DatanodeReportType>(enumSet1, class1);
      enumSetWritable0.getConf();
      Class<InterruptedException> class2 = InterruptedException.class;
      Class<InterruptedException> class3 = InterruptedException.class;
      Class<InterruptedException> class4 = InterruptedException.class;
      // Undeclared exception!
      try { 
        Chain.setReducerConf((Configuration) null, class2, class3, class4, class1, (Configuration) null, "t$o}2E+");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      Chain chain0 = new Chain(true);
      Class<HdfsConstants.DatanodeReportType> class0 = HdfsConstants.DatanodeReportType.class;
      EnumSet<HdfsConstants.DatanodeReportType> enumSet0 = EnumSet.noneOf(class0);
      EnumSet<HdfsConstants.DatanodeReportType> enumSet1 = enumSet0.clone();
      Class<HdfsConstants.DatanodeReportType> class1 = HdfsConstants.DatanodeReportType.class;
      EnumSetWritable<HdfsConstants.DatanodeReportType> enumSetWritable0 = new EnumSetWritable<HdfsConstants.DatanodeReportType>(enumSet1, class1);
      enumSetWritable0.getConf();
      Configuration configuration0 = new Configuration(true);
      Class<WebHdfsFileSystem> class2 = WebHdfsFileSystem.class;
      Class<WebHdfsFileSystem> class3 = WebHdfsFileSystem.class;
      Class<WebHdfsFileSystem> class4 = WebHdfsFileSystem.class;
      // Undeclared exception!
      Chain.setMapperConf(true, configuration0, class2, class0, class3, class4, configuration0, 965, "");
  }

  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      TestGenericWritable.Baz testGenericWritable_Baz0 = new TestGenericWritable.Baz();
      testGenericWritable_Baz0.getConf();
      Class<InterruptedException> class0 = InterruptedException.class;
      Class<InterruptedException> class1 = InterruptedException.class;
      Class<InterruptedException> class2 = InterruptedException.class;
      Class<InterruptedException> class3 = InterruptedException.class;
      // Undeclared exception!
      try { 
        Chain.validateKeyValueTypes(true, (Configuration) null, class1, class0, class2, class3, 524287, "");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      Chain chain0 = new Chain(false);
      chain0.joinAllThreads();
      JobConf jobConf0 = new JobConf(false);
      Class<InterruptedException> class0 = InterruptedException.class;
      Class<InterruptedException> class1 = InterruptedException.class;
      // Undeclared exception!
      try { 
        Chain.setMapperConf(false, jobConf0, class0, class0, class0, class1, jobConf0, 4044, "default");
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // org.apache.hadoop.io.serializer.WritableSerialization cannot be cast to org.apache.hadoop.io.serializer.Serialization
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      Chain.KeyValuePair<DelegationTokenRenewer.RenewAction<WebHdfsFileSystem>, Chain.ChainBlockingQueue<InterruptedException>> chain_KeyValuePair0 = new Chain.KeyValuePair<DelegationTokenRenewer.RenewAction<WebHdfsFileSystem>, Chain.ChainBlockingQueue<InterruptedException>>(true);
      Chain chain0 = new Chain(true);
      chain0.createBlockingQueue();
      LongWritable.DecreasingComparator longWritable_DecreasingComparator0 = new LongWritable.DecreasingComparator();
      Configuration configuration0 = longWritable_DecreasingComparator0.getConf();
      // Undeclared exception!
      chain0.setup(configuration0);
  }

  @Test(timeout = 4000)
  public void test26()  throws Throwable  {
      Chain chain0 = new Chain(true);
      // Undeclared exception!
      try { 
        chain0.runMapper((TaskInputOutputContext) null, 4346);
        fail("Expecting exception: IndexOutOfBoundsException");
      
      } catch(IndexOutOfBoundsException e) {
         //
         // Index: 4346, Size: 0
         //
         verifyException("java.util.ArrayList", e);
      }
  }

  @Test(timeout = 4000)
  public void test27()  throws Throwable  {
      boolean boolean0 = true;
      Chain chain0 = new Chain(true);
      // Undeclared exception!
      try { 
        chain0.runMapper((TaskInputOutputContext) null, 4346);
        fail("Expecting exception: IndexOutOfBoundsException");
      
      } catch(IndexOutOfBoundsException e) {
         //
         // Index: 4346, Size: 0
         //
         verifyException("java.util.ArrayList", e);
      }
  }

  @Test(timeout = 4000)
  public void test28()  throws Throwable  {
      TestGenericWritable.Baz testGenericWritable_Baz0 = new TestGenericWritable.Baz();
      testGenericWritable_Baz0.getConf();
      Class<InterruptedException> class0 = InterruptedException.class;
      Class<InterruptedException> class1 = InterruptedException.class;
      // Undeclared exception!
      Chain.setMapperConf(false, (Configuration) null, class0, class0, class1, class0, (Configuration) null, 524287, "");
  }

  @Test(timeout = 4000)
  public void test29()  throws Throwable  {
      boolean boolean0 = false;
      Chain chain0 = new Chain(false);
      TestGenericWritable.FooGenericWritable testGenericWritable_FooGenericWritable0 = new TestGenericWritable.FooGenericWritable();
      testGenericWritable_FooGenericWritable0.getConf();
      // Undeclared exception!
      try { 
        chain0.setup((Configuration) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.mapreduce.lib.chain.Chain", e);
      }
  }

  @Test(timeout = 4000)
  public void test30()  throws Throwable  {
      Chain chain0 = new Chain(true);
      Chain.ChainBlockingQueue<InterruptedException> chain_ChainBlockingQueue0 = chain0.new ChainBlockingQueue<InterruptedException>();
      chain_ChainBlockingQueue0.enqueue((InterruptedException) null);
      String string0 = Chain.getPrefix(true);
      assertEquals("mapreduce.chain.mapper", string0);
  }

  @Test(timeout = 4000)
  public void test31()  throws Throwable  {
      Chain chain0 = new Chain(true);
      Class<HdfsConstants.DatanodeReportType> class0 = HdfsConstants.DatanodeReportType.class;
      EnumSet<HdfsConstants.DatanodeReportType> enumSet0 = EnumSet.allOf(class0);
      EnumSetWritable<HdfsConstants.DatanodeReportType> enumSetWritable0 = new EnumSetWritable<HdfsConstants.DatanodeReportType>(enumSet0);
      Subject subject0 = new Subject();
      Class<UserGroupInformation.AuthenticationMethod> class1 = UserGroupInformation.AuthenticationMethod.class;
      Set<UserGroupInformation.AuthenticationMethod> set0 = subject0.getPrivateCredentials(class1);
      enumSet0.retainAll(set0);
      enumSetWritable0.getConf();
      // Undeclared exception!
      try { 
        chain0.setup((Configuration) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.mapreduce.lib.chain.Chain", e);
      }
  }

  @Test(timeout = 4000)
  public void test32()  throws Throwable  {
      Chain chain0 = new Chain(false);
      chain0.joinAllThreads();
      JobConf jobConf0 = new JobConf(false);
      Chain chain1 = new Chain(true);
      assertFalse(chain1.equals((Object)chain0));
  }

  @Test(timeout = 4000)
  public void test33()  throws Throwable  {
      Chain.KeyValuePair<Chain.ChainBlockingQueue<InterruptedException>, RecordReader<InterruptedException, InterruptedException>> chain_KeyValuePair0 = new Chain.KeyValuePair<Chain.ChainBlockingQueue<InterruptedException>, RecordReader<InterruptedException, InterruptedException>>(true);
      Chain chain0 = new Chain(true);
      chain0.joinAllThreads();
      int int0 = 435;
      // Undeclared exception!
      try { 
        chain0.getConf(435);
        fail("Expecting exception: IndexOutOfBoundsException");
      
      } catch(IndexOutOfBoundsException e) {
         //
         // Index: 435, Size: 0
         //
         verifyException("java.util.ArrayList", e);
      }
  }

  @Test(timeout = 4000)
  public void test34()  throws Throwable  {
      boolean boolean0 = false;
      Chain chain0 = new Chain(false);
      TestGenericWritable.Bar testGenericWritable_Bar0 = new TestGenericWritable.Bar();
      testGenericWritable_Bar0.getConf();
      Class<InterruptedException> class0 = InterruptedException.class;
      Class<InterruptedException> class1 = InterruptedException.class;
      // Undeclared exception!
      try { 
        Chain.checkReducerAlreadySet(false, (Configuration) null, "lx`;{,", false);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.mapreduce.lib.chain.Chain", e);
      }
  }

  @Test(timeout = 4000)
  public void test35()  throws Throwable  {
      Chain chain0 = new Chain(true);
      Class<InterruptedException> class0 = InterruptedException.class;
      Class<InterruptedException> class1 = InterruptedException.class;
      Class<InterruptedException> class2 = InterruptedException.class;
      // Undeclared exception!
      try { 
        Chain.setReducerConf((Configuration) null, class1, class2, class2, class0, (Configuration) null, ":");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test36()  throws Throwable  {
      boolean boolean0 = false;
      Job job0 = null;
      Class<WrappedMapper> class0 = WrappedMapper.class;
      Class<InterruptedException> class1 = InterruptedException.class;
      Class<InterruptedException> class2 = InterruptedException.class;
      Chain chain0 = new Chain(false);
      int int0 = 57343;
      TestGenericWritable.Baz testGenericWritable_Baz0 = new TestGenericWritable.Baz();
      testGenericWritable_Baz0.getConf();
      Class<InterruptedException> class3 = InterruptedException.class;
      // Undeclared exception!
      try { 
        Chain.setReducerConf((Configuration) null, class0, class2, class1, class3, (Configuration) null, "");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test37()  throws Throwable  {
      Chain chain0 = new Chain(true);
      LongWritable.DecreasingComparator longWritable_DecreasingComparator0 = new LongWritable.DecreasingComparator();
      Configuration configuration0 = longWritable_DecreasingComparator0.getConf();
      // Undeclared exception!
      Chain.getChainElementConf(configuration0, "zkx$%!RN[Qw0[z");
  }

  @Test(timeout = 4000)
  public void test38()  throws Throwable  {
      Chain chain0 = new Chain(true);
      Chain.KeyValuePair<FileSystemCounterGroup.FSCounter, InterruptedException> chain_KeyValuePair0 = new Chain.KeyValuePair<FileSystemCounterGroup.FSCounter, InterruptedException>(true);
  }

  @Test(timeout = 4000)
  public void test39()  throws Throwable  {
      String string0 = Chain.getPrefix(false);
      assertEquals("mapreduce.chain.reducer", string0);
      
      TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction typeDescription_Generic_AnnotationReader_Dispatcher_CreationAction0 = TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction.INSTANCE;
      TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction typeDescription_Generic_AnnotationReader_Dispatcher_CreationAction1 = TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction.INSTANCE;
      Chain.KeyValuePair<TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction, TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction> chain_KeyValuePair0 = new Chain.KeyValuePair<TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction, TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction>(typeDescription_Generic_AnnotationReader_Dispatcher_CreationAction0, typeDescription_Generic_AnnotationReader_Dispatcher_CreationAction1);
      Chain.KeyValuePair<FileSystemCounterGroup.FSCounter, InterruptedException> chain_KeyValuePair1 = new Chain.KeyValuePair<FileSystemCounterGroup.FSCounter, InterruptedException>(true);
      boolean boolean0 = true;
      Class<InterruptedException> class0 = InterruptedException.class;
      JobConf jobConf0 = null;
      try {
        jobConf0 = new JobConf(class0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.util.ClassUtil", e);
      }
  }

  @Test(timeout = 4000)
  public void test40()  throws Throwable  {
      Chain.getPrefix(false);
      TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction typeDescription_Generic_AnnotationReader_Dispatcher_CreationAction0 = TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction.INSTANCE;
      Chain.KeyValuePair<TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction, TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction> chain_KeyValuePair0 = new Chain.KeyValuePair<TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction, TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction>(typeDescription_Generic_AnnotationReader_Dispatcher_CreationAction0, typeDescription_Generic_AnnotationReader_Dispatcher_CreationAction0);
      Chain.KeyValuePair<FileSystemCounterGroup.FSCounter, InterruptedException> chain_KeyValuePair1 = new Chain.KeyValuePair<FileSystemCounterGroup.FSCounter, InterruptedException>(true);
  }

  @Test(timeout = 4000)
  public void test41()  throws Throwable  {
      String string0 = Chain.MAPPER_OUTPUT_KEY_CLASS;
      Chain chain0 = new Chain(false);
      Configuration configuration0 = new Configuration(false);
      Chain.checkReducerAlreadySet(false, configuration0, "mapreduce.chain.mapper.output.key.class", false);
      Class<InterruptedException> class0 = InterruptedException.class;
      Class<InterruptedException> class1 = InterruptedException.class;
      // Undeclared exception!
      try { 
        Chain.setMapperConf(false, configuration0, class0, class1, class1, class0, configuration0, 111, "mapreduce.chain.mapper.output.key.class");
       //  fail("Expecting exception: ClassCastException");
       // Unstable assertion
      } catch(ClassCastException e) {
         //
         // org.apache.hadoop.io.serializer.WritableSerialization cannot be cast to org.apache.hadoop.io.serializer.Serialization
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test42()  throws Throwable  {
      Chain chain0 = new Chain(false);
      TestGenericWritable.FooGenericWritable testGenericWritable_FooGenericWritable0 = new TestGenericWritable.FooGenericWritable();
      testGenericWritable_FooGenericWritable0.getConf();
      // Undeclared exception!
      try { 
        Chain.checkReducerAlreadySet(false, (Configuration) null, ",\\F[6,D}v{cDJ`1", false);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.mapreduce.lib.chain.Chain", e);
      }
  }

  @Test(timeout = 4000)
  public void test43()  throws Throwable  {
      Chain.getPrefix(false);
      Chain chain0 = new Chain(false);
      chain0.getReducer();
      Configuration configuration0 = new Configuration(false);
      Chain.checkReducerAlreadySet(false, configuration0, "mapreduce.chain.reducer", false);
      Class<InterruptedException> class0 = InterruptedException.class;
      Class<InterruptedException> class1 = InterruptedException.class;
      Class<TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction> class2 = TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction.class;
      EnumSetWritable<HdfsConstants.DatanodeReportType> enumSetWritable0 = null;
      try {
        enumSetWritable0 = new EnumSetWritable<HdfsConstants.DatanodeReportType>((EnumSet<HdfsConstants.DatanodeReportType>) null);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // The EnumSet argument is null, or is an empty set but with no elementType provided.
         //
         verifyException("org.apache.hadoop.io.EnumSetWritable", e);
      }
  }

  @Test(timeout = 4000)
  public void test44()  throws Throwable  {
      boolean boolean0 = false;
      Chain chain0 = new Chain(false);
      chain0.createBlockingQueue();
      Chain.ChainBlockingQueue<InterruptedException> chain_ChainBlockingQueue0 = chain0.new ChainBlockingQueue<InterruptedException>();
      chain_ChainBlockingQueue0.interrupt();
      Configuration configuration0 = new Configuration();
      String string0 = "wZt<1h";
      // Undeclared exception!
      Job.getInstance(configuration0, "wZt<1h");
  }

  @Test(timeout = 4000)
  public void test45()  throws Throwable  {
      Chain chain0 = new Chain(false);
      JobConf jobConf0 = new JobConf(false);
      Chain chain1 = new Chain(false);
      chain1.isMap = false;
      chain1.createBlockingQueue();
      JobConf jobConf1 = new JobConf();
  }

  @Test(timeout = 4000)
  public void test46()  throws Throwable  {
      TestGenericWritable.Bar testGenericWritable_Bar0 = new TestGenericWritable.Bar();
      testGenericWritable_Bar0.getConf();
      // Undeclared exception!
      try { 
        Chain.getIndex((Configuration) null, (String) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.mapreduce.lib.chain.Chain", e);
      }
  }

  @Test(timeout = 4000)
  public void test47()  throws Throwable  {
      Chain chain0 = new Chain(false);
      Chain.ChainBlockingQueue<InterruptedException> chain_ChainBlockingQueue0 = chain0.new ChainBlockingQueue<InterruptedException>();
      chain_ChainBlockingQueue0.interrupt();
      chain_ChainBlockingQueue0.enqueue((InterruptedException) null);
  }

  @Test(timeout = 4000)
  public void test48()  throws Throwable  {
      String string0 = Chain.MAPPER_OUTPUT_KEY_CLASS;
      Chain chain0 = new Chain(true);
      // Undeclared exception!
      try { 
        chain0.getConf(1);
        fail("Expecting exception: IndexOutOfBoundsException");
      
      } catch(IndexOutOfBoundsException e) {
         //
         // Index: 1, Size: 0
         //
         verifyException("java.util.ArrayList", e);
      }
  }

  @Test(timeout = 4000)
  public void test49()  throws Throwable  {
      boolean boolean0 = true;
      Chain chain0 = new Chain(true);
      // Undeclared exception!
      try { 
        chain0.getConf((-1));
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // no message in exception (getMessage() returned null)
         //
      }
  }

  @Test(timeout = 4000)
  public void test50()  throws Throwable  {
      boolean boolean0 = false;
      Chain chain0 = new Chain(false);
      // Undeclared exception!
      try { 
        chain0.getConf(0);
        fail("Expecting exception: IndexOutOfBoundsException");
      
      } catch(IndexOutOfBoundsException e) {
         //
         // Index: 0, Size: 0
         //
         verifyException("java.util.ArrayList", e);
      }
  }

  @Test(timeout = 4000)
  public void test51()  throws Throwable  {
      TestGenericWritable.Baz testGenericWritable_Baz0 = new TestGenericWritable.Baz();
      testGenericWritable_Baz0.getConf();
      Class<WebHdfsFileSystem> class0 = WebHdfsFileSystem.class;
      Class<WebHdfsFileSystem> class1 = WebHdfsFileSystem.class;
      Class<InterruptedException> class2 = InterruptedException.class;
      Class<InterruptedException> class3 = InterruptedException.class;
      // Undeclared exception!
      try { 
        Chain.validateKeyValueTypes(true, (Configuration) null, class0, class1, class2, class3, 100, "*1&:)ldgs3@j.");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test52()  throws Throwable  {
      Chain chain0 = new Chain(true);
      Class<HdfsConstants.DatanodeReportType> class0 = HdfsConstants.DatanodeReportType.class;
      EnumSet<HdfsConstants.DatanodeReportType> enumSet0 = EnumSet.noneOf(class0);
      EnumSet<HdfsConstants.DatanodeReportType> enumSet1 = enumSet0.clone();
      Class<HdfsConstants.DatanodeReportType> class1 = HdfsConstants.DatanodeReportType.class;
      EnumSetWritable<HdfsConstants.DatanodeReportType> enumSetWritable0 = new EnumSetWritable<HdfsConstants.DatanodeReportType>(enumSet1, class1);
      enumSetWritable0.getConf();
      Class<InterruptedException> class2 = InterruptedException.class;
      Class<InterruptedException> class3 = InterruptedException.class;
      Class<InterruptedException> class4 = InterruptedException.class;
      // Undeclared exception!
      try { 
        Chain.validateKeyValueTypes(false, (Configuration) null, class0, class2, class3, class4, 100, "@(~PbbR");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test53()  throws Throwable  {
      Chain chain0 = new Chain(true);
      Chain.checkReducerAlreadySet(true, (Configuration) null, "V,xg2CrT]", true);
      Reducer<?, ?, ?, ?> reducer0 = chain0.getReducer();
      assertNull(reducer0);
  }

  @Test(timeout = 4000)
  public void test54()  throws Throwable  {
      TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction typeDescription_Generic_AnnotationReader_Dispatcher_CreationAction0 = TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction.INSTANCE;
      Chain.KeyValuePair<TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction, TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction> chain_KeyValuePair0 = new Chain.KeyValuePair<TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction, TypeDescription.Generic.AnnotationReader.Dispatcher.CreationAction>(typeDescription_Generic_AnnotationReader_Dispatcher_CreationAction0, typeDescription_Generic_AnnotationReader_Dispatcher_CreationAction0);
      Chain chain0 = new Chain(true);
      Reducer<?, ?, ?, ?> reducer0 = chain0.getReducer();
      assertNull(reducer0);
  }

  @Test(timeout = 4000)
  public void test55()  throws Throwable  {
      Chain chain0 = new Chain(true);
      Chain.checkReducerAlreadySet(true, (Configuration) null, "V,xg2CrT]", true);
      chain0.startAllThreads();
      Reducer<?, ?, ?, ?> reducer0 = chain0.getReducer();
      assertNull(reducer0);
  }

  @Test(timeout = 4000)
  public void test56()  throws Throwable  {
      Chain chain0 = new Chain(false);
      TestGenericWritable.FooGenericWritable testGenericWritable_FooGenericWritable0 = new TestGenericWritable.FooGenericWritable();
      testGenericWritable_FooGenericWritable0.getConf();
      Class<InterruptedException> class0 = InterruptedException.class;
      Class<InterruptedException> class1 = InterruptedException.class;
      Class<SWebHdfsFileSystem> class2 = SWebHdfsFileSystem.class;
      Class<SWebHdfsFileSystem> class3 = SWebHdfsFileSystem.class;
      // Undeclared exception!
      try { 
        Chain.validateKeyValueTypes(false, (Configuration) null, class0, class1, class2, class3, 0, "");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test57()  throws Throwable  {
      Chain chain0 = new Chain(false);
      chain0.startAllThreads();
      List<Mapper> list0 = (List<Mapper>)chain0.getAllMappers();
      assertTrue(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void test58()  throws Throwable  {
      Chain chain0 = new Chain(false);
      Chain.ChainBlockingQueue<InterruptedException> chain_ChainBlockingQueue0 = chain0.new ChainBlockingQueue<InterruptedException>();
      chain_ChainBlockingQueue0.enqueue((InterruptedException) null);
  }

  @Test(timeout = 4000)
  public void test59()  throws Throwable  {
      TestGenericWritable.Baz testGenericWritable_Baz0 = new TestGenericWritable.Baz();
      testGenericWritable_Baz0.getConf();
      Class<InterruptedException> class0 = InterruptedException.class;
      Class<InterruptedException> class1 = InterruptedException.class;
      // Undeclared exception!
      try { 
        Chain.validateKeyValueTypes(false, (Configuration) null, class0, class0, class1, class0, 524287, "7@uy9b[?Qo2>$sz/9");
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test60()  throws Throwable  {
      JobConf jobConf0 = new JobConf(false);
      // Undeclared exception!
      try { 
        Chain.getChainElementConf(jobConf0, "mapreduce.map.env");
       //  fail("Expecting exception: ClassCastException");
       // Unstable assertion
      } catch(ClassCastException e) {
         //
         // org.apache.hadoop.io.serializer.WritableSerialization cannot be cast to org.apache.hadoop.io.serializer.Serialization
         //
         verifyException("org.apache.hadoop.io.serializer.SerializationFactory", e);
      }
  }
}
